---
title: "Analyzing the effect of the interaction between attachment style and internalizing behavior on school connectedness"
author: "Ian Douglas"
date: "12/12/2019"
output:
  html_document:
    number_sections: yes
    toc: yes
    df_print: paged
    toc_float:
      collapsed: no
      smooth_scroll: yes
---
- Full Github repositiory for this project's code and figures <a href="http://github.com/ijd2109/fragileFamilies">here</a>.
- <a href="http://fragilefamilies.princeton.edu">Data</a> sourced from and maintained by Princeton and Columbia Universities.

### Analysis Plan
Part 1: fitting the hypothesized model.
1. Compute correlations between the outcome, *age 15 connectedness at school (CS15)*, and the predictors: *internalizing behaviors (IB)* and *age 9 (CS9)*.
2. Examine mean differences between the groups, and variance ratios.
3. Compute bootstrap confidence intervals for variance ratios.
4. Conduct Welch's test to control Type I error rate while assessing the effect of the grouping variable because the variance ratios are in fact large.
5. The mean differences were found to be non-significant, but the hypothesis purports a crossing-type interaction, so plot the groups on the dimensions of IB (binned into high and low categories) and CS15.
6. The graphical evidence does suggest that an interaction exists, and that a useful grouping of subjects should be 'avoidant' and 'not avoidant'. 
7. Fit the interaction model: predict CS15 from the Group-by-IB interaction, controlling for the continuous covariate CS9.
8. Report the F-statistic and p-value to indicate the significance of the model, as well as the significant (and standardized) Beta coefficients as a measure of effect size for the significant covariate and the interaction.
9. Interpret the conclusion of the model: the significant interaction shows that after controlling for CS9, the negative effect of IB on CS15 is worsened for subjects exhibiting avoidant attachment with caregivers at age three.
Part 2: diagnostics and further interrogation.
10. Running model diagnostics, it appears the constant error variance assumption is not met.
11. Run a Box-Cox transformation inside a two-part hurdle (zero-inflation model).
12. This provides the model with the best fit and greatest loglikelihood.

### Load libraries
```{r, results='hide', message=FALSE}
require(effsize)
require(tidyverse)
require(car)
require(pscl)
```

### Read in data
```{r}
# convert from Tibble to data.frame
df = as.data.frame(readRDS("../../data/processed/modelData.rds")) # output of wrangling script
rownames(df) <- df$idnum
# finally, delete the rows for whom there are NA in the outcome column (only)
df = df %>%
  filter(!is.na(target))
```

# Compute correlations.
## First between IB and CS9 with CS15.
```{r}
# the continuous predictor
cor.test(df$target, df$internalizingSum, use = "complete.obs",
         alternative = "two")
# the year9 observation of outcome (to control for)
cor.test(df$target, df$yr9_CNCT_Sum, use = "complete.obs",
         alternative = "two")
# testing multicolinearity
cor.test(df$internalizingSum, df$yr9_CNCT_Sum, use = "complete.obs",
         alternative = "two")
```
 Both predictors are significantly correlated (though weakly) with the outcome. Weak correlation is observed between the predictors, but well below the range necessary to infer multicolinearity.

# Compare standardized mean differences, and conduct ANOVA. 
## First between the three groups individually on the outcome (CS15)
```{r}
secure_avoidant = df %>% filter(resistant == 0)
resistant_secure = df %>% filter(avoidant == 0)
resist_avoid = df %>% filter(secure == 0)
contrast_list = list(secure_avoidant, resistant_secure, resist_avoid)
effsize::cohen.d(d = contrast_list[[1]]$target, as.factor(contrast_list[[1]]$secure),
                 na.rm = TRUE)
effsize::cohen.d(d = contrast_list[[2]]$target, as.factor(contrast_list[[2]]$secure),
                 na.rm = TRUE)
effsize::cohen.d(d = contrast_list[[3]]$target, as.factor(contrast_list[[3]]$avoidant),
                 na.rm = TRUE)
```

## Now on covariate IB
```{r}
# secure v avoidant
effsize::cohen.d(d = contrast_list[[1]]$internalizingSum,
                 as.factor(contrast_list[[1]]$secure),
                 na.rm = TRUE)
# secure v resistant
effsize::cohen.d(d = contrast_list[[2]]$internalizingSum,
                 as.factor(contrast_list[[2]]$secure),
                 na.rm = TRUE)
# avoidant v resistant
effsize::cohen.d(d = contrast_list[[3]]$internalizingSum,
                 as.factor(contrast_list[[3]]$avoidant),
                 na.rm = TRUE)
```

None of the means differ on average between groups.

## Now fit the ANOVA, which assumes equal variances, to analyze mean heterogeneity that way.
```{r}
anova1 = lm(target ~ ch3att_codeabc, data = df)
anova(lm(target ~ 1, data = df), anova1)
```

## Following the omnibus test, the linear contrast between avoidant all other groups:
```{r}
# use the MSE from the residual variance of the ANOVA table above.
MSE = 5.292
# Derive the vector of coefficients (adding up to zero).
cj = c("avoidant" = -1, "secure" = .5, "resistant" = .5)
# compile the within group sample sizes:
nj = sapply(unique(df$ch3att_codeabc), function(x) {
  Nj = sum(df$ch3att_codeabc==x); names(Nj) = x
  return(Nj)
})
# compute the vector of group means
mu = sapply(unique(df$ch3att_codeabc), function(x) {
  mean(as.vector(df[df$ch3att_codeabc==x, "target"]))
}); names(mu) <- unique(df$ch3att_codeabc)
psi = sum(mu*cj)
compute.t.contrast = function(MSE, coefs, Nj, psi) {
  out = psi/(sqrt(MSE*sum(coefs, Nj[match(names(Nj), names(coefs))])))
  return(out)
}
t.contrast = compute.t.contrast(MSE, cj, nj, psi)
c("value" = t.contrast, "p-value" = pt(t.contrast, df= anova1$df.residual))
```

The linear contrast is not significant.

# Assess assumptions about equal variances implicit in ANOVA.
## Variance ratios for between the avoidant and non-avoidant groups
```{r}
vrData = na.omit( # this will ultimately be the same data that is modelled.
  df %>% dplyr::select(avoidant, target, yr9_CNCT_Sum, internalizingSum)
)
sapply(c("target","yr9_CNCT_Sum","internalizingSum"), function(x) {
  return(var(vrData[vrData$avoidant == 1, x]) / var(vrData[vrData$avoidant == 0, x]))
})
```

## Bootstrap confidence intervals for each.
```{r}
B = 10000 # set the number of permutations
bootOut = data.frame( # prepare empty data frame for capturing results
  "target"= rep(NA, times = B),
  "yr9_CNCT_Sum"= rep(NA, times = B),
  "internalizingSum"= rep(NA, times = B)
)
# separate the data into groups outside the loop to save computational time
avoidantDf = vrData[vrData$avoidant == 1, ]
N_group_A = nrow(avoidantDf) # record the subsample size now as well
non_avoidantDf = vrData[vrData$avoidant == 0, ]
N_group_nonA = nrow(non_avoidantDf) # same for the non-avoidant group
# Run the loop:
for (i in 1:B) {
  bootAvoid = avoidantDf[sample(1:N_group_A, replace = TRUE), ]
  boot_non_Avoid = non_avoidantDf[sample(1:N_group_nonA, replace = TRUE), ]
  # compute all variance ratios (all three outcomes) in parallel
  bootOut[i, ] <- sapply(names(bootOut), function(x) { # names of bootOut are var names.
    # x is the variable name:
    return(var(bootAvoid[, x]) / var(boot_non_Avoid[, x]))
  })
}

## Results:
data.frame(row.names = names(bootOut),
  "estimate" = colMeans(bootOut),
  "CI_lwr" = sapply(bootOut, function(x) quantile(x, probs = 0.025)),
  "CI_upr" = sapply(bootOut, function(x) quantile(x, probs = 0.975))
)
```

Results indicate a degree of imbalance that is concerning, according to Rubin's (2001) guidelines, for CS measured at age 9 and 15 (but not the covariate IB). The scenario suggests that the group with a much smaller sample size, those of avoidant attachment styles, has the much higher variance in the domain of school connectedness at ages 9 and 15 than the other two groups. Thus, conducting traditional ANOVA is more likely to increase the risk of comitting Type I error. Instead, to test the significance of the grouping factor on CS15, I will use Welch's test.

# Visualization
## Plotting the distribution of the outcome measure within each group presents both the mean variability and variance heterogeneity in one plane.
### Retaining all three groups:
```{r,eval=FALSE}
# A density plot wil visualize the means and variances for each group as well:
pdf(file="../../plots/groupDensities.pdf", width = 12, height = 8, bg = "white")
densityPlot(df$target, g = df$ch3att_codeabc, 
            legend = list(location = "topleft", title = 'Attachment Style'),
            xlab = "Connectedness at School", adjust = c(.7, 2, 2))
abline(v=mean(na.rm=TRUE,(df%>%filter(ch3att_codeabc=="avoidant"))$target), lwd =2)
abline(v=mean(na.rm=TRUE,(df%>%filter(ch3att_codeabc=="secure"))$target),lty=2,col=4,lwd =2)
abline(v=mean(na.rm=TRUE,(df%>%filter(ch3att_codeabc=="resistant"))$target),lty=3,col=6,lwd =2)
dev.off()
```

<img src="../../plots/groupDensities.pdf" alt="dplt"  width="720" height="480">

```{r, out.width="0.3\\linewidth", include=TRUE, fig.align="center", fig.cap=c("your caption"), echo=FALSE, eval = TRUE}
#knitr::include_graphics("../../plots/groupDensities.pdf")
```

### And between two groups
```{r, eval=FALSE}
density_Data = df %>% mutate_at(vars(avoidant), ~as.factor(ifelse(.==1,"avoidant","other")))
pdf(file="../../plots/binTWO_groupDensities.pdf", width = 12, height = 8, bg = "white")
densityPlot(density_Data$target, g = density_Data$avoidant, 
            legend = list(location = "topleft", title = 'Avoidant'),
            xlab = "Connectedness at School", adjust = c(.7, 2.3))
abline(v = mean(na.rm=TRUE,(density_Data%>%filter(avoidant=="avoidant"))$target), lwd =2)
abline(v=mean(na.rm=TRUE,(density_Data%>%filter(avoidant=="other"))$target),lty=2,col=4,lwd =2)
dev.off()
```

<img src="../../plots/binTWO_groupDensities.pdf" alt="dplt2"  width="720" height="480">

```{r, out.width="0.3\\linewidth", include=TRUE, fig.align="center", fig.cap=c("your caption"), echo=FALSE, eval = TRUE}
#knitr::include_graphics("../../plots/binTWO_groupDensities.pdf")
```

# Welch's one-way ANOVA corection for heteroskedasticity.
## Comparing the avoidant to the resistant group
```{r}
oneway.test(target ~ as.factor(avoidant), data = resist_avoid)
```

## Comparing the avoidant to the secure group
```{r}
oneway.test(target ~ as.factor(avoidant), data = secure_avoidant)
```

## Comparing the avoidant to the non-avoidant groups pooled
```{r}
oneway.test(target ~ as.factor(avoidant), data = df)
```

## All groups (omnibus) assuming unequal variances:
```{r}
oneway.test(target ~ ch3att_codeabc, data = df)
```

Conclusion: the groups alone do not explain a significant proportion in the variance of CS15.

# Plot the hypothesized interaction.
## At low and high levels of internalizing, plot group means for target
```{r, eval=FALSE}
# reformat data for plotting purposes.
plt_data = df %>%
  filter(!is.na(internalizingSum)) %>%
  group_by(ch3att_codeabc) %>%
  mutate(internalizing = ifelse(internalizingSum <= median(internalizingSum,na.rm = TRUE),
                                  "low","high")) %>%
  group_by(ch3att_codeabc, internalizing) %>%
  summarize_at(vars(internalizingSum, target), 
               list(~mean(., na.rm = TRUE), ~sd(., na.rm = TRUE))) %>%
  ungroup() %>%
  rename_at(vars(ch3att_codeabc), ~("Group"))

# generate plot:
plt <- ggplot(plt_data, aes(x = internalizing, y = target_mean, group = Group)) +
  geom_point(aes(color = Group)) +
  geom_line(aes(color = Group)) +
  ggtitle(label = "Mean Connectedness at School by Group and Level of Internalizing Behavior")

# display plot:
plt
```
```{r, eval=FALSE,echo=FALSE}
ggsave(plt, device = "pdf", file="../../plots/interaction_plot.pdf",
       width = 12, height = 8)
```
```{r, eval=FALSE,echo=FALSE}
save(plt, file = "../../plots/layers/plt_ggplotlayers_pdfinteraction_plot.RData")
```
```{r,eval=TRUE,echo=FALSE}
load("../../plots/layers/plt_ggplotlayers_pdfinteraction_plot.RData")
plt
```

## Binning into avoidant and non-avoidant groups, as per theorized interaction
```{r, eval=FALSE}
# format data for plotting purposes
plt_data2 = df %>% 
  mutate_at("avoidant", ~as.factor(ifelse(. == 1, "True", "False"))) %>%
  filter(!is.na(internalizingSum)) %>%
  mutate(internalizing = ifelse(internalizingSum <= median(internalizingSum,na.rm = TRUE),
                                  "low","high")) %>%
  group_by(avoidant, internalizing) %>%
  summarize_at(vars(internalizingSum, target), 
               list(~mean(., na.rm = TRUE), ~sd(., na.rm = TRUE))) %>%
  ungroup()

# generate plot:
plt2 <- ggplot(plt_data2, aes(x = internalizing, y = target_mean, group = avoidant)) +
  geom_point(aes(color = avoidant)) +
  geom_line(aes(color = avoidant)) +
  ggtitle(label = "Mean Connectedness at School by Group and Level of Internalizing Behavior")

# display plot:
plt2
```
```{r, eval=FALSE,echo=FALSE}
ggsave(plt2, device = "pdf", file="../../plots/2group_int_plot.pdf",
       width = 12, height = 8)
```
```{r, eval=FALSE,echo=FALSE}
save(plt2, file = "../../plots/layers/plt2_ggplotlayers_2group_int_plot.RData")
```
```{r,eval=TRUE,echo=FALSE}
load("../../plots/layers/plt2_ggplotlayers_2group_int_plot.RData")
plt2
```

This crossing type interaction is a possible explanation for the undeteceted mean differences, and insignificant main effect of group (both when binning created two- and three-groups). This provides graphical evidence that an interaction model may still be appropriate, and subsequent modeling (below) will follow from this conclusion.

# Regression Analyses
## Fit the model
```{r}
# note, the interaction is drawn between internalization and the dummy code for avoidant
# Thus, implicitly, there are two groups in this model.

model = lm(target ~ yr9_CNCT_Sum + # year 15 connectedness controlling for that of year 9
             internalizingSum*avoidant, # the int. btwn internalizing and avoidant
           data = df) # the full data.
#saveRDS(model, "../../output/interactionModel_TWOGrp.rds")
```
```{r, eval=FALSE,echo=FALSE}
saveRDS(model, "../../output/interactionModel_TWOGrp.rds")
```
```{r, eval=TRUE, echo=FALSE}
model = readRDS("../../output/interactionModel_TWOGrp.rds")
```

## Regression estimates
```{r}
summary(model)
```

## ANOVA table:
```{r}
summary(aov(model))
```